---
title: "RCrawler101-201512"
author: "Mansun Kuo"
date: "`r Sys.Date()`"
subtitle: "Week 2"
css: css/ioslides.css
#widescreen: yes
output: 
  ioslides_presentation: 
    widescreen: yes
---

```{r include=FALSE}
library(knitr)
knitr::opts_chunk$set(warning = TRUE,
                      echo = TRUE,
                      message = TRUE,
                      fig.align='center',
                      cache=FALSE)
```

## Hello RStudio

<img src="img/hello_rstudio.png" width=800>


## Must-known keyboard shortcuts

[AllRStudio keyboard shortcuts](https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts)

Description                      | Windows & Linux    | Mac
-------------------------------- | ------------------ | ---
Show Keyboard Shortcut Reference | Alt+Shift+K        | Option+Shift+K
Attempt completion / Indent	     | Tab or Ctrl+Space  | Tab or Command+Space
Run current line/selection       | Ctrl+Enter         | Command+Enter
Comment/uncomment current line/selection | Ctrl+Shift+C | Command+Shift+C
Save active document             | Ctrl+S             | Command+S
Reindent lines                   | Ctrl+I             | Command+I


## Basic R recap

- ?, ??, how to read manuel
- vector, listï¼ŒDataFrame, matrix
- str, type, class
- for, if/else ifelse 
- apply/lapply/sapply, unlist
- do.call
- [magrittr](https://github.com/smbache/magrittr)


## magrittr

Pipe argument to right-hand side with `%>%`

- x %>% f is equivalent to f(x)
- x %>% f(y) is equivalent to f(x, y)
- x %>% f %>% g %>% h is equivalent to h(g(f(x)))
- x %>% f(y, .) is equivalent to f(y, x)
- x %>% f(y, z = .) is equivalent to f(y, z = x)


# Web connector in R


## Web connector in R

- httr: Dealing with [HTTP methods](http://www.w3schools.com/tags/ref_httpmethods.asp) in R
- RCurl:
    - General network client interface for R 
    - A wrapper of libcurl
    


## HTTP method recap



## httr


# Data parser in R

## Data parser in R

- rvest
- xml2
- XML


## rvest

A web scraper designed to work with magrittr.

- Create a html document with `read_html`
- Select parts of a document using css selectors or xpath
    - `html_nodes(doc, css = "<css selector>")`
    - `html_nodes(doc, xpath = "<css selector>")`
- Extract components with 
    - `html_name()`: the name of the tag
    - `html_text()`: all text inside the tag
    - `html_attr()`: contents of a single attribute
    - `html_attrs()`: all attributes
    - `html_table`: parse tables into data frames 


## rvest - 2


## A simple HTML document

[demo](data/demo.html)

<div class="code_block">
```{r}
library(magrittr)
doc = readLines("data/demo.html") %>%
    paste(collapse = "\n")
cat(doc)
```
</div>


## Create HTML document 

```{r}
library(rvest)
doc = read_html("data/demo.html")
doc
```


## Extract with css

```{r}
doc %>% 
    html_nodes(css = ".character") %>% 
    html_text
doc %>% 
    html_nodes(css = "#title > .link") %>% 
    html_text
```


## Extract with xpath

```{r}
doc %>% 
    html_nodes(xpath = "//*[@class='character']") %>% 
    html_text
doc %>% 
    html_nodes(xpath = "//div[@id='title']/a") %>% 
    html_text
```


## Extract name of tag

```{r}
node = doc %>% 
    html_nodes(css = "#summary") %>% 
    html_name
node
```


## Extract link

```{r}
link = doc %>% 
    html_nodes(xpath = "/html/body/div[@id='title']/a") %>%
    html_attr("href")
link
```


## Extract table

```{r}
students = doc %>% 
    html_nodes(xpath = "//table") %>%
    html_table()
students
```


# Save your data

## Ways to save your data in R

- download.file: save html, jpeg, etc
- write.csv: save your data.frame into csv
- RSQLite: SQLite connector in R


## Download files

```{r cache = TRUE}
dest_dir = "data/download"
dir.create(dest_dir, showWarnings = FALSE, recursive = TRUE)

# Download whole HTML file
download.file("https://www.r-project.org/", 
              file.path(dest_dir, "r-project.org.html"))

# Download image
download.file("https://www.r-project.org/Rlogo.png",
              file.path(dest_dir, "Rlogo.png"))

list.files(dest_dir)
```



##

```{r}
ptt_gossiping = "https://www.ptt.cc/bbs/Gossiping/index.html"
```





## Case study

- https://docs.google.com/presentation/d/15ly6dUAQYatNMgquAxwqS205WYK3jxPnFbNlMfbk3nI/embed?start=false&loop=false&delayms=60000&slide=id.g70dd955d5_0_179
- https://github.com/datasci-info/PyCrawler101-201510/tree/master/pycrawler101/case_studies




