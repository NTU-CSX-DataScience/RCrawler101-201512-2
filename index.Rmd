---
title: "RCrawler101-201512"
author: "Mansun Kuo"
date: "`r Sys.Date()`"
subtitle: "Week 2"
css: css/ioslides.css
#widescreen: yes
output: 
  ioslides_presentation: 
    widescreen: yes
---

```{r include=FALSE}
library(knitr)
knitr::opts_chunk$set(warning = TRUE,
                      echo = TRUE,
                      message = TRUE,
                      fig.align='center',
                      cache=FALSE)
```

## Hello RStudio

<img src="img/hello_rstudio.png" width=800>


## Must-known keyboard shortcuts

[AllRStudio keyboard shortcuts](https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts)

Description                      | Windows & Linux    | Mac
-------------------------------- | ------------------ | ---
Show Keyboard Shortcut Reference | Alt+Shift+K        | Option+Shift+K
Attempt completion / Indent	     | Tab or Ctrl+Space  | Tab or Command+Space
Run current line/selection       | Ctrl+Enter         | Command+Enter
Comment/uncomment current line/selection | Ctrl+Shift+C | Command+Shift+C
Save active document             | Ctrl+S             | Command+S
Reindent lines                   | Ctrl+I             | Command+I


## R recap

- ?, ??, how to read manuel
- vector, list，DataFrame, matrix
- str, type, class
- for, if/else ifelse 
- apply/lapply/sapply, unlist
- do.call
- [magrittr](https://github.com/smbache/magrittr)
- [data.table](https://cran.r-project.org/web/packages/data.table/index.html)


## magrittr

Pipe argument to right-hand side with `%>%`

- x %>% f is equivalent to f(x)
- x %>% f(y) is equivalent to f(x, y)
- x %>% f %>% g %>% h is equivalent to h(g(f(x)))
- x %>% f(y, .) is equivalent to f(y, x)
- x %>% f(y, z = .) is equivalent to f(y, z = x)


## data.table

- What
    - An enhanced version of data.frames
    - Optimize most heavy works in C
    - Minimize redundant copies
- Why
    - Speed
    - Automatically optimization
    - Total solution for ETL
    - Concise syntax

## data.table: General Form

**DT[i, j, by]**

R:     i       j               by
----- ------- --------------- -----------  
SQL:   where   select/update   group by
----- ------- --------------- -----------

<br>

Take **DT**, subset rows using *i*, then calculate *j*, grouped by *by*.


## data.table: a quick overview

- **data.table**: get a data.table
- **fread**: read text file into data.table
- **.**: an abbreviation of list within data.table 
- **:=**: add/remove/update a column by reference.
- **by**: to summarize by each group. 
- **.SD**: **S**ubset of **D**ata.table. It's a data table that holds the data for the current group defined using *by*. 
- **.SDcols** specifies the columns that returned in .SD.
- **.N**: returns the number of rows in the subset.
- **DT[ ... ][ ... ][ ... ]**: chaining. Avoid intermediate assignment
- **rbindlist**: same as do.call("rbind", l) on data.frames, but faster.
- **copy**: to do a deep copy


# Crawler's toolkits in R

## Crawler's toolkits in R

- [rvest](https://cran.r-project.org/web/packages/rvest/index.html): a web scraper based on httr and xml2
- [httr](https://cran.r-project.org/web/packages/httr/index.html): toolkit of  [HTTP methods](http://www.w3schools.com/tags/ref_httpmethods.asp) in R
- [xml2](https://cran.r-project.org/web/packages/xml2/index.html): xml parser based on libxml2
- [RCurl](https://cran.r-project.org/web/packages/RCurl/index.html): a wrapper of libcurl
- [XML](https://cran.r-project.org/web/packages/XML/index.html) & : XML parser


## rvest

A web scraper designed to work with magrittr.

- Create a html document with `read_html()`
- Select parts of a document using css selectors or xpath
    - `html_nodes(doc, css = "<css selector>")`
    - `html_nodes(doc, xpath = "<css selector>")`
- Extract components with 
    - `html_name()`: the name of the tag
    - `html_text()`: all text inside the tag
    - `html_attr()`: contents of a single attribute
    - `html_attrs()`: all attributes
    - `html_table`: parse tables into data frames 


## A simple HTML document

[demo](data/demo.html)

<div class="code_block">
```{r}
library(magrittr)
doc = readLines("data/demo.html") %>%
    paste(collapse = "\n")
cat(doc)
```
</div>


## Create HTML document 

```{r}
library(rvest)
doc = read_html("data/demo.html")
doc
```


## Extract with css

```{r}
doc %>% 
    html_nodes(css = ".character") %>% 
    html_text
doc %>% 
    html_nodes(css = "#title > .link") %>% 
    html_text
```


## Extract with xpath

```{r}
doc %>% 
    html_nodes(xpath = "//*[@class='character']") %>% 
    html_text
doc %>% 
    html_nodes(xpath = "//div[@id='title']/a") %>% 
    html_text
```


## Case study: 東森房屋

- [Result](example/etwarm.html)
- [Code](example/etwarm.R)


## Exercise

Modify previous example to get the price of ouse


## Extract name of tag

```{r}
node = doc %>% 
    html_nodes(css = "#summary") %>% 
    html_name
node
```


## Extract link

```{r}
link = doc %>% 
    html_nodes(xpath = "/html/body/div[@id='title']/a") %>%
    html_attr("href")
link
```


## Extract table

```{r}
students = doc %>% 
    html_nodes(xpath = "//table") %>%
    html_table()
students
```


## httr

- Basic Features:
    - HTTP verbs: `GET()`, `POST()`, `HEAD()`, `PUT()` and `DELETE()`
    - `http_status`: Translate http status code
       [HTTP status](https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81) code
    - `headers()`: Access response headers
    - `content()`: Retrieve the contents of a request
    - `set_cookies()`: set cookles
- Can be used with rvest 


## Take a look at header

Try to use TAB to explore object in  

<div class="code_block">
```{r}
library(httr)
Target_URL = "http://tw.stock.yahoo.com/d/s/major_2451.html"
res = HEAD(Target_URL)
class(res)
res$content
http_status(res)
res$status_code
head = headers(res)
head$`content-type`
res$headers$`content-type`
str(res)
```
</div>


## Basic

Use `GET()` to make a request

<div class="code_block">
```{r cache=TRUE}
library(httr)
url = "http://ecshweb.pchome.com.tw/search/v3.3/all/results?q=sony&page=1&sort=rnk/dc"
res = GET(url)
res
class(res)
typeof(res)
str(res)
res$content
res$request
res
```
</div>


## Query

You can assign query parameter with `query()` 

```{r}
url2 = "http://ecshweb.pchome.com.tw/search/v3.3/all/results"
res2 = GET(url, query = list(q="sony", page="1", sort="rnk/dc"))
identical(res$content, res2$content)
```


## String Template

```{r}
library(whisker)
url_template = "http://ecshweb.pchome.com.tw/search/v3.3/all/results?q={{q}}&page={{page}}&sort={{sort}}"
url3 = whisker.render(url_template, list(q="sony", page="1", sort="rnk/dc"))
url3
res3 = GET(url3)
identical(res$content, res3$content)
```


## Parse JSON format

Yun can parse 
[JSON](http://www.w3schools.com/json/)
with jsonlite in R

<div class="code_block">
```{r}
library(jsonlite)
library(magrittr)
res_df = content(res, as = "text") %>% 
    fromJSON() %>% 
    .$prods     # equivelent to (function(x) {x$prods})
str(res_df)
```
</div>


## Parsed with loop

<div class="code_block">
```{r}
res_list = content(res, as = "parsed")
str(res_list$prods[[1]])
res_df2 = data.frame()
for (i in 1:length(res_list$prods)) {
    res_df2 = rbind(res_df2, 
                    data.frame(res_list$prods[[i]], 
                               stringsAsFactors = FALSE))
}
identical(res_df, res_df2)
```
</div>


##

<div class="code_block">
```{r}
res_df3 = data.frame(do.call(rbind, res_list$prods))
identical(res_df, res_df3)
str(res_df3)
```
</div>


## Use with rvest

##  

<div class="code_block">
```{r}
library(httr)
library(rvest)

Target_URL = "http://tw.stock.yahoo.com/d/s/major_2451.html"
res = GET(Target_URL)
doc_str = iconv(content(res, type = "text", encoding = "big5"))

dat1 = doc_str %>% 
    read_html() %>% 
    html_nodes(xpath = "//table[1]//table[2]") %>% 
    html_table(header=TRUE)
class(dat1)
class(dat1[[1]])
dat1

dat2 = read_html(Target_URL, encoding = "big5") %>% 
    html_nodes(xpath = "//table[1]//table[2]") %>% 
    html_table(header=TRUE)
identical(dat1, dat2)
```


## Exercise

[行政院環境保護署環境資源資料開放平台](http://opendata.epa.gov.tw/DevelopZone/Sample/UV/)提供了一系列的Restfuk Api供大家取用，請試著把
[紫外線即時監測資料](http://opendata.epa.gov.tw/webapi/api/rest/datastore/355000000I-000004/?format=json)的資料取回來並轉成data.frame


## POST

## Exercise: postGuestBook




# Save your data

## Ways to save your data in R

- write.csv: write data.frame as csv file
- download.file: save html, jpeg, etc
- writeBin: write binary object into disk
- RSQLite: SQLite connector in R


## write.csv

```{r}
write.csv(res_df, "data/pchome.csv", row.names = FALSE)
```


## download.file


```{r cache = TRUE}
dest_dir = "data/download"
dir.create(dest_dir, showWarnings = FALSE, recursive = TRUE)

# Download whole HTML file
download.file("https://www.r-project.org/", 
              file.path(dest_dir, "r-project.org.html"))



# Download image
download.file("https://www.r-project.org/Rlogo.png",
              file.path(dest_dir, "Rlogo.png"))

list.files(dest_dir)
```


## writeBin

```{r}
r = GET("http://opendata.epa.gov.tw/webapi/api/rest/datastore/355000000I-000004/?format=json")
bin = content(r, "raw")
writeBin(bin, "data/download/uv.json")
```



## RSQLite




## RCurl
    
- General network client interface for R 
- A wrapper of libcurl


## Case study

- https://docs.google.com/presentation/d/15ly6dUAQYatNMgquAxwqS205WYK3jxPnFbNlMfbk3nI/embed?start=false&loop=false&delayms=60000&slide=id.g70dd955d5_0_179
- https://github.com/datasci-info/PyCrawler101-201510/tree/master/pycrawler101/case_studies
- https://github.com/agilearning/RCrawlers/tree/master/CaseStudies
- http://whizzalan.github.io/RCrawlerCrashCourse/


